{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "\n",
    "from time import sleep\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:\\\\Users\\\\ritvik\\\\Desktop\\\\YouTubeScraping\\\\YouTubeScraping-c52225391da2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a client\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_as_table(data, headers):\n",
    "    df = pd.DataFrame(data=data, columns=[i[0] for i in headers])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query, retval=False, many=False, data=None, verbose=False):\n",
    "    conn = sqlite3.connect('videos.db')\n",
    "\n",
    "    #create a cursor\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    if many:\n",
    "        cur.executemany(query, data)\n",
    "    else:\n",
    "        cur.execute(query)\n",
    "    \n",
    "    result = cur.fetchall()\n",
    "    \n",
    "    if verbose:\n",
    "\n",
    "        print(display_as_table(result, cur.description))\n",
    "\n",
    "    #close connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    if retval:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_info(video_id, fields):\n",
    "    \"\"\"\n",
    "    Call the GoogleVision API to get characteristics of a video thumbnail\n",
    "    video_id: the id of the video we care about\n",
    "    fields: subset of four possible thumbain entities: ['label', 'face', 'image', 'text']\n",
    "    cur: the cursor of the database\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    result = execute_query('SELECT EntityType From ThumbnailEntities WHERE VideoId = \"%s\"'%video_id, True)\n",
    "    existing_entities = [item[0] for item in result]\n",
    "    fields = [f for f in fields if f not in existing_entities]\n",
    "    \n",
    "    #if no fields to process, return\n",
    "    if len(fields) == 0:\n",
    "        return\n",
    "    \n",
    "    #try to get the thumbnail url for this video\n",
    "    result = execute_query('SELECT ThumbnailURL From Videos WHERE VideoId = \"%s\"'%video_id, True)\n",
    "    \n",
    "    #if this video not found, return \n",
    "    if len(result) == 0:\n",
    "        return\n",
    "    \n",
    "    #get the thumbnail url\n",
    "    thumbnail_url = result[0][0]\n",
    "        \n",
    "    #set this thumbnail as the url\n",
    "    image = types.Image()\n",
    "    image.source.image_uri = thumbnail_url\n",
    "    \n",
    "    data_dict = dict()\n",
    "    \n",
    "    #if we should do label detection\n",
    "    if 'label' in fields:\n",
    "    \n",
    "        #### LABEL DETECTION ######\n",
    "\n",
    "        response_label = client.label_detection(image=image)\n",
    "\n",
    "        label_data = [{'label': label.description, 'score': label.score} for label in response_label.label_annotations if label.score > 0.5]\n",
    "        \n",
    "        data_dict['label'] = label_data\n",
    "\n",
    "        ##########################\n",
    "        \n",
    "    if 'face' in fields:\n",
    "    \n",
    "        #### FACIAL DETECTION ######\n",
    "\n",
    "        response_face = client.face_detection(image=image)\n",
    "        \n",
    "        face_data = []\n",
    "\n",
    "        for face_detection in response_face.face_annotations:\n",
    "            d = {\n",
    "                'confidence': face_detection.detection_confidence,\n",
    "                'joy': face_detection.joy_likelihood,\n",
    "                'sorrow': face_detection.sorrow_likelihood,\n",
    "                'surprise': face_detection.surprise_likelihood,\n",
    "                'anger': face_detection.anger_likelihood\n",
    "            }\n",
    "            face_data.append(d)\n",
    "            \n",
    "        data_dict['face'] = face_data\n",
    "\n",
    "        ##########################\n",
    "        \n",
    "    if 'image' in fields:\n",
    "    \n",
    "        #### IMAGE PROPERTIES ######\n",
    "\n",
    "        response_image = client.image_properties(image=image)\n",
    "        \n",
    "        image_data = []\n",
    "\n",
    "        for c in response_image.image_properties_annotation.dominant_colors.colors[:3]:\n",
    "            d = {\n",
    "                'color': c.color,\n",
    "                'score': c.score,\n",
    "                'pixel_fraction': c.pixel_fraction\n",
    "            }\n",
    "            image_data.append(d)\n",
    "            \n",
    "        data_dict['image'] = image_data\n",
    "\n",
    "        ##########################\n",
    "        \n",
    "    if 'text' in fields:\n",
    "    \n",
    "        #### TEXT DETECTION ######\n",
    "        \n",
    "        text_data = []\n",
    "\n",
    "        response_text = client.text_detection(image=image)\n",
    "\n",
    "        for r in response_text.text_annotations[:1]:\n",
    "            d = {\n",
    "                'text': r.description\n",
    "            }\n",
    "            text_data.append(d)\n",
    "            \n",
    "        data_dict['text'] = text_data\n",
    "\n",
    "        ##########################\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_thumbnail_entities(video_ids, batch):\n",
    "    \n",
    "    data_to_insert = []\n",
    "    for idx, data_dict in enumerate(batch):\n",
    "        for field, data in data_dict.items():\n",
    "            for entity in data:\n",
    "                data_to_insert.append([video_ids[idx], field, str(entity)])\n",
    "    \n",
    "    try:\n",
    "        execute_query('INSERT INTO ThumbnailEntities (VideoId, EntityType, Data) VALUES (?,?,?)', retval=False, many=True, data=data_to_insert)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_thumbnail_stats(vid_ids, fields):\n",
    "    \n",
    "    batch_size = 20\n",
    "\n",
    "    curr_batch = []\n",
    "    curr_vid_ids = []\n",
    "    \n",
    "    for idx, vid_id in enumerate(vid_ids):\n",
    "    \n",
    "        data_dict = get_image_info(vid_id, fields)\n",
    "\n",
    "        if data_dict != None:\n",
    "            curr_batch.append(data_dict)\n",
    "            curr_vid_ids.append(vid_id)\n",
    "        \n",
    "        if (idx % batch_size == batch_size - 1) or (idx + 1 == len(vid_ids)):\n",
    "            insert_into_thumbnail_entities(curr_vid_ids, curr_batch)\n",
    "            print('Processed %s videos'%(idx+1))\n",
    "            curr_batch = []\n",
    "            curr_vid_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sigmoid_data.csv')\n",
    "vid_ids = list(df.video_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 videos\n",
      "Processed 40 videos\n",
      "Processed 60 videos\n",
      "Processed 80 videos\n",
      "Processed 100 videos\n",
      "Processed 120 videos\n",
      "Processed 140 videos\n",
      "Processed 160 videos\n",
      "Processed 180 videos\n",
      "Processed 200 videos\n",
      "Processed 220 videos\n",
      "Processed 240 videos\n",
      "Processed 260 videos\n",
      "Processed 280 videos\n",
      "Processed 300 videos\n",
      "Processed 320 videos\n",
      "Processed 340 videos\n",
      "Processed 360 videos\n",
      "Processed 380 videos\n",
      "Processed 400 videos\n",
      "Processed 420 videos\n",
      "Processed 440 videos\n",
      "Processed 460 videos\n",
      "Processed 480 videos\n",
      "Processed 500 videos\n",
      "Processed 520 videos\n",
      "Processed 540 videos\n",
      "Processed 560 videos\n",
      "Processed 580 videos\n",
      "Processed 600 videos\n",
      "Processed 620 videos\n",
      "Processed 640 videos\n",
      "Processed 660 videos\n",
      "Processed 680 videos\n",
      "Processed 700 videos\n",
      "Processed 720 videos\n",
      "Processed 740 videos\n",
      "Processed 760 videos\n",
      "Processed 780 videos\n",
      "Processed 800 videos\n",
      "Processed 820 videos\n",
      "Processed 840 videos\n",
      "Processed 860 videos\n",
      "Processed 880 videos\n",
      "Processed 900 videos\n",
      "Processed 920 videos\n",
      "Processed 940 videos\n",
      "Processed 960 videos\n",
      "Processed 980 videos\n",
      "Processed 1000 videos\n",
      "Processed 1020 videos\n",
      "Processed 1040 videos\n",
      "Processed 1060 videos\n",
      "Processed 1080 videos\n",
      "Processed 1100 videos\n",
      "Processed 1120 videos\n",
      "Processed 1140 videos\n",
      "Processed 1160 videos\n",
      "Processed 1180 videos\n",
      "Processed 1200 videos\n",
      "Processed 1220 videos\n",
      "Processed 1240 videos\n",
      "Processed 1260 videos\n",
      "Processed 1280 videos\n",
      "Processed 1300 videos\n",
      "Processed 1320 videos\n",
      "Processed 1340 videos\n",
      "Processed 1360 videos\n",
      "Processed 1380 videos\n",
      "Processed 1400 videos\n",
      "Processed 1420 videos\n",
      "Processed 1440 videos\n",
      "Processed 1460 videos\n",
      "Processed 1480 videos\n",
      "Processed 1500 videos\n",
      "Processed 1520 videos\n",
      "Processed 1540 videos\n",
      "Processed 1560 videos\n",
      "Processed 1580 videos\n",
      "Processed 1600 videos\n",
      "Processed 1620 videos\n",
      "Processed 1640 videos\n",
      "Processed 1660 videos\n",
      "Processed 1680 videos\n",
      "Processed 1700 videos\n",
      "Processed 1720 videos\n",
      "Processed 1740 videos\n",
      "Processed 1760 videos\n",
      "Processed 1780 videos\n",
      "Processed 1800 videos\n",
      "Processed 1819 videos\n"
     ]
    }
   ],
   "source": [
    "insert_thumbnail_stats(vid_ids, ['label', 'face', 'image', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
